# SesAI Platform - Docker Compose Configuration
# Includes: sesai, vllm, freeswitch

version: "3.8"

services:
  # ==========================================================================
  # SesAI Voice Agent Service
  # ==========================================================================
  sesai:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: sesai-agent
    restart: unless-stopped
    ports:
      - "8080:8080"   # HTTP API (future)
      - "8765:8765"   # AudioSocket
    environment:
      # STT Configuration
      - STT_MODEL=${STT_MODEL:-large-v3-turbo}
      - STT_DEVICE=cuda
      - STT_COMPUTE_TYPE=int8
      # TTS Configuration (Chatterbox)
      - TTS_DEVICE=cuda
      - TTS_LANGUAGE=tr
      - TTS_REFERENCE_AUDIO=${TTS_REFERENCE_AUDIO:-}
      # LLM Configuration
      - VLLM_BASE_URL=http://vllm:8000/v1
      - LLM_MODEL=${LLM_MODEL:-Qwen/Qwen3-8B-AWQ}
      # AudioSocket Configuration
      - AUDIOSOCKET_HOST=0.0.0.0
      - AUDIOSOCKET_PORT=8765
      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
    volumes:
      # Cache models locally to avoid re-downloading
      - huggingface-cache:/home/sesai/.cache/huggingface
      # Optional: Reference audio for voice cloning
      - ./voice-references:/app/voice-references:ro
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      vllm:
        condition: service_healthy
    networks:
      - sesai-network
    healthcheck:
      test: ["CMD", "python", "-c", "print('ok')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

  # ==========================================================================
  # vLLM OpenAI-compatible LLM Server
  # ==========================================================================
  vllm:
    image: vllm/vllm-openai:latest
    container_name: sesai-vllm
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN:-}
    command: >
      --model ${LLM_MODEL:-Qwen/Qwen3-8B-AWQ}
      --quantization awq
      --max-model-len 4096
      --gpu-memory-utilization 0.6
      --host 0.0.0.0
      --port 8000
    volumes:
      - huggingface-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - sesai-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s

  # ==========================================================================
  # FreeSWITCH PBX for Telephony
  # ==========================================================================
  freeswitch:
    image: signalwire/freeswitch:latest
    container_name: sesai-freeswitch
    restart: unless-stopped
    ports:
      - "5060:5060/udp"   # SIP UDP
      - "5060:5060/tcp"   # SIP TCP
      - "5061:5061/tcp"   # SIP TLS
      - "16384-16484:16384-16484/udp"  # RTP media
    volumes:
      - ../freeswitch/dialplan:/etc/freeswitch/dialplan/default:ro
      - ../freeswitch/conf:/etc/freeswitch/autoload_configs:ro
      - freeswitch-recordings:/var/lib/freeswitch/recordings
    networks:
      - sesai-network
    depends_on:
      - sesai

# ==========================================================================
# Networks
# ==========================================================================
networks:
  sesai-network:
    driver: bridge

# ==========================================================================
# Volumes
# ==========================================================================
volumes:
  huggingface-cache:
    driver: local
  freeswitch-recordings:
    driver: local
